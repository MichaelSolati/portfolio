---
title: I'm Getting Serious Déjà Vu... But This Time It's Different
description: The AI "gold rush" feels just like the 2015 bootcamp days, but the data shows a harsher reality. Here's why the market is fundamentally different and what it really takes to be an engineer today.
tags: ai,programming,career,learning
pubDate: Tue Nov 18 2025 08:00:00 GMT-0800 (Pacific Standard Time)
hero: /blog/im-getting-serious-deja-vu-but-this-time-its-different/hero.webp
---

I've been getting the strangest sense of déjà vu lately.

I'm based in the Bay Area, and as I look at the tech landscape today, I'm transported back to somewhere around 2014 or 2015. I was just starting my own journey as a developer, and the coding bootcamps were _exploding_. It wasn't just a feeling: [the market grew by 138% in 2015](https://www.coursereport.com/reports/2015-coding-bootcamp-market-size-study) alone, with graduates jumping from just over 6,700 to more than 16,000 in a single year. I would know, I was one of them! (Shoutout to the A100 team.) Every tech meetup, every "hack night," you'd meet a fresh-faced new developer, portfolio in hand, bright-eyed and ready to build.

The hiring pool was flooded, and we all had to claw our way into this industry, reading every blog post, breaking (and fixing) side projects, and slowly building careers. Our path, which felt so personal, was actually just a [packaged and sold 12-week "sprint."](https://www.coursereport.com/reports/2015-coding-bootcamp-market-size-study#tuition)

I remember feeling this perplexing mix of curiosity and concern. Was my job, my hard-won knowledge, or just a commodity?

Fast forward to today. I've had the opportunity to build a successful career for myself and feel comfortable and knowledgeable in my domain, and yet I'm getting that same feeling. But this time, the "bootcamp" isn't a school. It's GitHub Copilot. It's ChatGPT. It's the entire era of AI-vibe-coding.

I see demos on Twitter (not calling it X) and LinkedIn of people building entire, complex applications with a few well-worded prompts. And that old, familiar question is back: Are our skills about to be commoditized... again?

My initial instinct was to say, "It's the same story, just a new tool." But the more I looked at the data, the more I realized my déjà vu was misleading. The 2010s "bootcamp boom" and the 2020s "AI wave" are fundamentally different beasts.

<figure>
  <img src="/blog/im-getting-serious-deja-vu-but-this-time-its-different/dejavu.webp" alt="The 'glitch in the Matrix' scene: An animated GIF where Neo observes a black cat walk past him twice in the exact same way, a repeating anomaly that makes him say 'déjà vu.'" style="margin-left: auto; margin-right: auto;" height="338" width="600">
  <figcaption style="margin-left: auto; margin-right: auto; width: fit-content;">Whoa. Déjà vu.</figcaption>
</figure>

## The Old "Filter": Horizontal Saturation

The bootcamp boom was, at its heart, a promise of access. It promised that anyone with the drive (and the tuition) could become a developer. It was a "gold rush" for skills, and it minted many developers who were fantastic at the "how." They knew how to build a to-do list, a simple blog, or a full-stack project with the MERN/MEAN stack.

But "how" is only half the story.

The challenge back then was one of **horizontal saturation**. The market saw a massive influx of new, similarly-skilled junior talent, all competing for a rapidly _expanding_ pool of junior-level roles.

After that initial wave, the market _calibrated_. A "Great Filter" emerged. It turned out that getting a job and _keeping_ a job were two very different things.

The filter wasn't "Can you code?"

It became:

- Can you read, understand, and debug someone _else's_ code?
- Can you sit in a planning meeting and translate a vague business need into a concrete technical spec?
- Can you explain _why_ you chose PostgreSQL over MongoDB for this specific feature, and can you defend that trade-off?
- Can you write a meaningful test?

The filter separated _coding_ from _engineering_. Coding is the act of writing code. Engineering is the discipline of designing, building, maintaining, and owning systems in the real world.

The market wasn't saturated with _engineers_. It was saturated with people who could _code_. The "cream" that rose to the top were the folks who understood that the 12-week program was just the starting line, not the finish.

## The New "Filter": Vertical Compression & Pipeline Elimination

This is where the parallel breaks down. The 2020s market isn't just saturated; it's being squeezed from two directions by forces we didn't have in 2015.

### 1. The Squeeze from the Top: "Vertical Compression"

Today's market is defined by **vertical compression**. The 2022-2024 period didn't just see a hiring slowdown; it saw [over 660,000 tech workers lose their jobs](https://www.wearedevelopers.com/en/magazine/418/software-engineering-over-saturated). Crucially, these layoffs weren't confined to junior staff. They included "top-paid and most experienced developers in the industry" from elite companies like Google, Meta, and Amazon.

<figure>
  <img src="/blog/im-getting-serious-deja-vu-but-this-time-its-different/layoffs.webp" alt="An illustration of an office layoff, showing four diverse employees with sad expressions holding boxes of their belongings in front of empty office cubicles." style="margin-left: auto; margin-right: auto;" height="576" width="1024">
  <figcaption style="margin-left: auto; margin-right: auto; width: fit-content;">660k+ developers lost their jobs from 2022 to 2024</figcaption>
</figure>

This creates a "domino effect" that is crushing the job market from the top down:

- Laid-off senior architects compete for senior developer roles.
- Displaced senior developers compete for mid-level roles.
- Displaced mid-level developers compete for junior roles.

This leaves entry-level and new "AI wave" graduates in an almost impossible position. In 2015, I was competing with other bootcamp grads on a relatively even playing field. In 2025, new grads are competing with laid-off FAANG (MANGA?) engineers with years of experience.

### 2. The Squeeze from the Bottom: "Pipeline Elimination"

At the _exact_ same time, AI is automating the very tasks that new developers used to cut their teeth on.

The real, immediate impact of AI is not replacing senior engineers. In fact, one study found that, for complex, real-world tasks, current AI tools [_slowed_ experienced developers](https://metr.org/blog/2025-07-10-early-2025-ai-experienced-os-dev-study/), taking them 19% _longer_ to complete their work.

The actual danger is at the very _bottom_ of the pipeline. A [2024 survey](https://stackoverflow.blog/2025/09/10/ai-vs-gen-z/) found **70% of hiring managers** believe AI can do the jobs of _interns_, and **37% of employers** stated they would rather "hire" AI than a recent graduate.

So, new developers are squeezed from the top by "vertical compression" and from the bottom by AI-driven "task automation," all while fighting for a job pool that continues to shrink.

## The Real Story: The "Great Capital Reallocation"

It's easy to look at this and say, "See! AI is taking the jobs!" But the data shows that's, at best, a "smokescreen".

Classic economic forces drove the vast majority of layoffs: correcting "post-pandemic overhiring" and reacting to a harsh macro-economic shift (like rising interest rates) that made capital expensive. In fact, [only 3-4% of job cuts](https://nearshoreamericas.com/u-s-layoffs-surge-and-blaming-ai-is-part-of-the-smokescreen/) through September 2025 were _explicitly_ tied to AI.

So why are CEOs at companies like Amazon and Google _publicly_ blaming AI for "reorganizations" and "efficiency"?

It's a strategic narrative for Wall Street. "AI Washing" allows a company to frame a "weak" narrative ("We made a mistake and overhired") as a "strong" one ("We are a lean, AI-first company pivoting to the future").

This narrative obscures the _real_, long-term shift: **The Great Capital Reallocation**.

This is the "great tech paradox": CEOs hand out pink slips with one hand while signing billion-dollar AI investments with the other. For the first time, companies are strategically reallocating billions of dollars, shifting spending from Operational Expenditures, like our salaries, to Capital Expenditures, like massive, expensive GPU clusters.

The layoffs are not just savings; they are the _source of funding_ for this new, capital-intensive arms race.

- **Amazon:** Announced [14,000 corporate layoffs in October 2025](https://www.crn.com/news/cloud/2025/amazon-confirms-14-000-layoffs-says-ai-innovation-reason-for-reducing-roles), citing AI-driven "efficiency". At the _exact same time_, they announced a **$100 billion** capital expenditure plan for 2025 to expand AI and cloud data centers.
- **Meta:** Cut [over 21,000 jobs](https://www.mindandmetrics.com/blog/tech-layoffs-ai-google-job-cuts) under its "Year of Efficiency". Simultaneously, it _raised_ its 2025 capital expenditure guidance to [**$70-72 billion**](https://www.theguardian.com/technology/2025/oct/29/meta-earnings-report) to acquire a staggering [1.3 million+ GPUs](https://www.pcmag.com/news/zuckerberg-looks-to-double-metas-gpu-stock-to-13-million-for-ai-training).

This is the new "Great Filter." The challenge is not just "Can you code?" It's "Can you justify your $150k salary to a company that is 'strategically reallocating' its budget to a $100 billion hardware plan?"

<figure>
  <img src="/blog/im-getting-serious-deja-vu-but-this-time-its-different/gpu_sales.webp" alt="A bar chart from Omdia Research of Nvidia H100 GPU Shipments by Customer showing estimated 2023 shipments." style="margin-left: auto; margin-right: auto;" height="1125" width="1121">
  <figcaption style="margin-left: auto; margin-right: auto; width: fit-content;">These 65,000 GPUs, priced from $25k-$40k, represent a staggering $1.6 to $2.6 BILLION investment by these tech giants. <a href="https://www.theverge.com/2023/12/4/23987953/the-gpu-haves-and-have-nots" target="_blank">(chart source)</a></figcaption>
</figure>

## Don't Fear the Tool, Master the Craft (Now More Than Ever)

This isn't a post to scare anyone. And it's _definitely_ not meant to be elitist or to gatekeep. On the contrary, this is a pragmatic call to action.

The "chaff," then and now, are those who look for a shortcut and mistake it for the entire journey. The "cream" will be the same as it ever was: the curious, the pragmatic, the problem-solvers.

> "History Doesn't Repeat Itself, but It Often Rhymes"
>
> ~ Mark Twain

But the "filter" _is_ different, and it's harsher.

The new filter won't be, "Can you write a function to sort an array?" (AI will do that).

The new filter will be:

- Can you validate that the 1,000+ lines of code the AI just generated are secure, performant, and (most importantly) _correct_?
- Can you architect a system of prompts, validations, and tests to get the output you need, every time, reliably?
- Can you debug a subtle logic error when the AI 'hallucinates' a solution that _looks_ right but is fundamentally wrong?
- Can you take full, systems-level ownership when the AI-generated part fails at 3 AM?

The new "cream" will be the **AI-Assisted Engineer**, not the **Prompt-Jockey**. The "chaff" will be those who trust the black box, copy and paste the output, and call it a day.

This new wave won't make good engineers obsolete; it will make them more potent than ever. But the path _into_ the industry is undeniably harder. New developers have to compete on three fronts: against other grads, against laid-off veterans, and against AI automating the entry-level pipeline.

So I'm not perplexed anymore. I'm focused. The answer is the same as it was in 2015, only more so: Don't just learn the "how." Master the "why." Understand the _craft_. Be the one who can build the _whole_ system, not just one function.

I'm curious, what do you all think? What skills are _you_ focusing on to make sure you're on the "engineering" side of this new, very different line? Let me know!
